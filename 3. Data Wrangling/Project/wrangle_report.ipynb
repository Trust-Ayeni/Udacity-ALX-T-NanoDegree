{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (wrangle_report) on Wrangle and Analyze Data project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created by Ayeni Trust Olamilekan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is stated in today's world that real-life data rarely comes clean, and this is entirely accurate. As a result, abilities such as data wrangling, analyzing, cleansing, and visualizing are essential for becoming a skilled data analyst. Working on this project allowed me to hone these abilities and take the next step on my path to become a professional data analyst. The following are the actions I did during the wrangling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taken steps and details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Data gathering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed all three pieces of data for the data collection stage, as indicated in the **\"Data Gathering\"** section of the `wrangle_act.ipynb` notebook. I had already been provided the file `twitter archive enhanced.csv` to manually download. I downloaded it, then uploaded it and used the pandas **'.read csv()'** function to read the data into a pandas DataFrame. The second dataset, `image predictions.tsv`, was made available for programmatic download. I used Python's **'Requests'** package to complete the work. Finally, a third dataset including (at a minimum) tweet ID, retweet count, and favorite count was required to be downloaded from Twitter. I used my twitter developer account's API credentials and Python's **'Tweepy'** package to do this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data assesing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After acquiring all three kinds of data, examine them visually and programmatically for quality and tidiness concerns in the data assessment stage. In the relevant **\"Accessing Data\"** portion of the **'wrangle_act.ipynb'** Jupyter Notebook, I discovered and recorded eight quality concerns and two tidiness issues below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Data cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleansed all of the concerns I identified when analyzing throughout the data cleaning process. This cleaning was done in the `wrangle_act.ipynb` matching **\"Cleaning Data\"** section.\n",
    "\n",
    "In this stage, I did the following tasks.\n",
    "\n",
    "1. I made a duplicate of each original data before cleaning.\n",
    "2. During the cleaning process, I followed the define-code-test framework and documented everything.\n",
    "3. Finally, I combined all three datasets into a single clean master pandas DataFrame and saved it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Data storing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I placed the cleaned master DataFrame in a CSV file with the primary one named `twitter archive master.csv`, following the appropriate **\"Storing Data\"** part of the `wrangle act.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Data analyzing and visualizing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data Analyzing and Visualizing stage of my `wrangle act.ipynb` Jupyter Notebook, I analyzed and visualized the wrangled data in the same relevant section. As needed, I created three insights and one graphic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Data reporting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed a 300-600 word written report named `wrangle report.html` (current) to summarize my data wrangling efforts as the last data reporting stage. In addition, I generated a 250-word-minimum written report named `act report.html` that conveys all of the findings and provides the data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I previously stated, this assignment was really beneficial in preparing me to advance as a future data analyst. I learned new functions and methods in Python, Numpy, Pandas, Matplotlib, Excel, and libraries as a result of this assignment. In addition, I learnt how to acquire data using Twitter APIs, as well as how to obtain and extract data from online data sources and web sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17c06682289c648123aaf5266b09decc0b5cbfda0ba4811c7d49ddbab2030d1b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
